{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ],
   "id": "ccba7c313e61f4df"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a47f1ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4a47f1ef",
    "outputId": "27094287-6bbe-4fff-add8-be2c34d801b8"
   },
   "source": [
    "from wordcloud import WordCloud\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as goa\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data Preprocessing"
   ],
   "id": "11ed80bf2ca675fc"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7daDN0eKM7bH",
   "metadata": {
    "id": "7daDN0eKM7bH"
   },
   "source": [
    "df = pd.read_csv(\"twitter_validation.csv\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c4bcf9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "6c4bcf9c",
    "outputId": "0811bfed-6e3c-4065-dc1a-9976ac17cde8",
    "scrolled": true
   },
   "source": [
    "# Label the columns\n",
    "df.columns = [\"tweet_id\",\"place\", \"sentiments\", \"tweets\"]\n",
    "df = df.drop(\"place\", axis=1)\n",
    "df"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4fb5568a",
   "metadata": {
    "id": "4fb5568a"
   },
   "source": [
    "# Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21afdf30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21afdf30",
    "outputId": "566b165a-5a1d-4c9a-898d-8ad4514f2cbc"
   },
   "source": [
    "df.info()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d2228d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "3d2228d0",
    "outputId": "3fda9a5f-e256-4e07-a9fa-f851613a13cf",
    "scrolled": true
   },
   "source": [
    "# Identify inconsistencies\n",
    "#The code `duplicate_rows = df[df.duplicated()]` is identifying and storing the duplicate rows in the DataFrame `df`. The `df.duplicated()` function returns a boolean Series indicating whether each row is a duplicate or not. By passing this boolean Series as a filter to the DataFrame `df`, only the duplicate rows are selected and stored in the variable `duplicate_rows`.\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "duplicate_rows"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f9f4465",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f9f4465",
    "outputId": "7235c141-5e9d-4d74-ec2c-04c8550165b4"
   },
   "source": [
    "# Identify missing values\n",
    "#The code is calculating the number of missing values in each column of the DataFrame `df`. It uses the `isna()` method to check for missing values and the `sum()` method to calculate the total number of missing values in each column. The result is stored in the variable `missing_values`.\n",
    "missing_values = df.isna().sum()\n",
    "missing_values"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74e841e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "74e841e9",
    "outputId": "30865628-7c05-4c3d-d2b3-b805846927fe"
   },
   "source": [
    "# removing duplicates\n",
    "\n",
    "df.drop_duplicates(inplace = True)\n",
    "\n",
    "# Remove the duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df['tweets'] = df['tweets'].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "stopw = set(stopwords.words(\"english\"))\n",
    "\n",
    "print(stopw)\n",
    "df[\"tweets\"] = df['tweets'].apply(lambda x: ' '.join(\n",
    "    [word.lower() for word in x.split() if word.lower() not in stopw]))\n",
    "\n",
    "\n",
    "def convert_list_to_str(l):\n",
    "    st = \"\"\n",
    "    for i in l:\n",
    "        st = st+i+\" \"\n",
    "    st = st[:-1]\n",
    "    return st\n",
    "\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+|\\d+')\n",
    "df[\"tweets_new\"] = df[\"tweets\"].apply(tokenizer.tokenize)\n",
    "df[\"tweets_new\"] = df[\"tweets_new\"].apply(convert_list_to_str)\n",
    "\n",
    "\n",
    "df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c91af7f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 906
    },
    "id": "c91af7f4",
    "outputId": "ced6b95e-1a0b-4241-8a87-317f8948c56c"
   },
   "source": [
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # Default to noun if no mapping found\n",
    "\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    # tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    # words = word_tokenize(sentence)\n",
    "    words = sentence.split()\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    lemmatized_words = [lemmatizer.lemmatize(\n",
    "        word, get_wordnet_pos(pos_tag)) for word, pos_tag in pos_tags]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "df[\"tweets_new\"] = df[\"tweets_new\"].apply(lemmatize_sentence)\n",
    "print(df)\n",
    "\n",
    "df[\"tweets\"] = df[\"tweets_new\"]\n",
    "\n",
    "# df[\"tweets\"] = df[\"tweets_new\"].apply(convert_list_to_str)\n",
    "df = df.drop(columns=[\"tweets_new\"])\n",
    "# print(df)\n",
    "\n",
    "#fill 0 in mum\n",
    "df['tweets'] = df['tweets'].fillna(0)\n",
    "\n",
    "# Save the dataframe\n",
    "df.to_csv(\"tweet_clean.csv\", index=False)\n",
    "df\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef4b79cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ef4b79cc",
    "outputId": "c39df0f0-2081-4b35-c522-383a79c9c6a3"
   },
   "source": [
    "#check for duplicates\n",
    "df.duplicated().sum()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a392a91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7a392a91",
    "outputId": "c3ccb68e-2b69-4847-d147-1b6707c7a968"
   },
   "source": [
    "#check null\n",
    "df['tweets'].isnull().sum()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0609e972",
   "metadata": {
    "id": "0609e972"
   },
   "source": [
    "# Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb76673b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "cb76673b",
    "outputId": "5b2326a5-e44e-4fe0-dac9-d9badb757c29"
   },
   "source": [
    "#`df.describe().T` is transposing the output of the `describe()` method on a DataFrame `df`. The `describe()` method provides summary statistics of the numerical columns in the DataFrame, such as count, mean, standard deviation, minimum, maximum, and quartiles. By applying `.T` after `describe()`, the output is transposed, meaning the rows become columns and vice versa. This can be useful for better readability or for further analysis of the summary statistics.\n",
    "df.describe().T"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "006b4366",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "id": "006b4366",
    "outputId": "b854b830-919d-4cdb-fff6-43d6f72aeae8"
   },
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='sentiments', data=df)\n",
    "for container in plt.gca().containers:\n",
    "    plt.gca().bar_label(container, fmt='%.2f')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a4cc280",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "1a4cc280",
    "outputId": "611e1fca-7232-487b-b99e-61d7ae75720d"
   },
   "source": [
    "\n",
    "\n",
    "df_copy = df.copy()\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "# Every single column with categorical values will be converted.\n",
    "object_cols = ['sentiments']\n",
    "df_copy[object_cols] = df_copy[object_cols].astype(str)\n",
    "\n",
    "df_copy[object_cols] = ordinal_encoder.fit_transform(df_copy[object_cols])\n",
    "\n",
    "df_copy.head()\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "# Every single column with categorical values will be converted.\n",
    "object_cols = ['tweet_id', 'sentiments', 'tweets']\n",
    "df[object_cols] = df[object_cols].astype(str)\n",
    "\n",
    "df[object_cols] = ordinal_encoder.fit_transform(df[object_cols])\n",
    "\n",
    "df.head()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85b1d1d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 999
    },
    "id": "85b1d1d6",
    "outputId": "b2205df0-7465-4f6e-fc14-64e0fcb0e211"
   },
   "source": [
    "\n",
    "plt.figure(figsize= (20,15))\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "sns.boxplot(x= df['tweet_id'], color='lightblue')\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "sns.boxplot(x= df['sentiments'], color='lightblue')\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "sns.boxplot(x= df['tweets'], color='lightblue')\n",
    "\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b80e44e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "b80e44e6",
    "outputId": "616d68d7-0f3c-42cb-9374-28b9314eec9f"
   },
   "source": [
    "\n",
    "\n",
    "# Load the cleaned data\n",
    "clean_df = pd.read_csv(\"tweet_clean.csv\")\n",
    "\n",
    "# Extract the sentiment words\n",
    "positive_words = clean_df[clean_df['sentiments'] == 'Positive']['tweets'].tolist()\n",
    "positive_words = [str(word) for word in positive_words]\n",
    "positive_wordcloud = WordCloud(width=1000, height=500).generate(' '.join(positive_words))\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(positive_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.title('Positive')\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "963d20b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711
    },
    "id": "963d20b9",
    "outputId": "7c588335-c0f6-40d2-aaaf-c3a1e47b0ba6"
   },
   "source": [
    "# Extract the sentiment words\n",
    "\n",
    "negative_words = clean_df[clean_df['sentiments'] == 'Negative']['tweets'].tolist()\n",
    "neutral_words = clean_df[clean_df['sentiments'] == 'Neutral']['tweets'].tolist()\n",
    "irrelevant_words = clean_df[clean_df['sentiments'] == 'Irrelevant']['tweets'].tolist()\n",
    "\n",
    "negative_words = [str(word) for word in negative_words]\n",
    "neutral_words = [str(word) for word in neutral_words]\n",
    "irrelevant_words = [str(word) for word in irrelevant_words]\n",
    "\n",
    "\n",
    "negative_wordcloud = WordCloud(width=1000, height=500).generate(' '.join(negative_words))\n",
    "neutral_wordcloud = WordCloud(width=1000, height=500).generate(' '.join(neutral_words))\n",
    "irrelevant_wordcloud = WordCloud(width=1000, height=500).generate(' '.join(irrelevant_words))\n",
    "\n",
    "# Display the word clouds\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(negative_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.title('Negative')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(neutral_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.title('Neutral')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(irrelevant_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.title('Irrelevant')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(positive_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.title('Positive')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ea7731e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "8ea7731e",
    "outputId": "0c8274a0-4dc3-4425-c090-811e435540be"
   },
   "source": [
    "\n",
    "fig = px.histogram(df, x='tweets', title='Tweets Distribution', barmode='group',\n",
    "                   color_discrete_sequence=['blue'])  # Set the color to blue\n",
    "fig.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bf40ce1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bf40ce1",
    "outputId": "78ba10ca-4b65-4a17-a7e3-e3fe2d3624bf"
   },
   "source": [
    "print(df['sentiments'].nunique())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6dcedd7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "c6dcedd7",
    "outputId": "2cb9e09c-213c-48aa-8dcd-7fdcc7a56122"
   },
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=df.tweets, y=df.tweet_id,hue=df.sentiments,palette= ['red','green','blue', 'yellow'] ,alpha=0.6)\n",
    "plt.title(\"Relationship between tweets and sentiments\")\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers and Pytorch Models"
   ],
   "id": "36bf10b06cdedab2"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "r5WGLUdR2VIb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r5WGLUdR2VIb",
    "outputId": "d94f9ab3-caff-405b-df4c-cb1c1cb69471"
   },
   "source": [
    "!pip install transformers"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "-VKExFLxfXah",
   "metadata": {
    "id": "-VKExFLxfXah"
   },
   "source": [
    "import re\n",
    "import numpy as np\n",
    "# import emoji as emoji\n",
    "import string\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "wAbjSJOXf60w",
   "metadata": {
    "id": "wAbjSJOXf60w"
   },
   "source": [
    "def data_process(data, labels):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    for sentence in data:\n",
    "        bert_inp = bert_tokenizer.__call__(sentence, max_length=36,\n",
    "                                           padding='max_length', pad_to_max_length=True,\n",
    "                                           truncation=True, return_token_type_ids=False)\n",
    "\n",
    "        input_ids.append(bert_inp['input_ids'])\n",
    "        attention_masks.append(bert_inp['attention_mask'])\n",
    "    input_ids = np.asarray(input_ids)\n",
    "    attention_masks = np.array(attention_masks)\n",
    "    labels = np.array(labels)\n",
    "    return input_ids, attention_masks, labels\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4lv7JyE2f63y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163,
     "referenced_widgets": [
      "3bb0fb7dc5c54f3f8e16f4cb25d9c8e4",
      "301a18fe83224f73babb22e264ee6a91",
      "1850bfffad004758a1eff8f0214ca096",
      "771b3019c7364f43879a0632d946015e",
      "4826a9443d90449bb9112f005a73b0f9",
      "38e2710afa6a4e7980776e356d81ef36",
      "e8c8569152ba4455961ed447fbc11c5c",
      "4e35cd93cc9345148a5a0f8a3f6eee06",
      "e07bec675dd84907b9864024c52538da",
      "771ed2bf8a2549e5a7f35e4d9a6d3311",
      "bc41aaa5134c4071a126e1e771076441",
      "22f3a1570e4048fa87a0a67793708ea8",
      "bb0bff7c20144c879e3a9857bfbfe4a0",
      "f1c6b457aa5443ed873b4104c951fd1a",
      "4cf79df228e14178ac64ebc11c9458ff",
      "aca06649bfb6448699b303b9104a6e87",
      "4050f16f9f0144babf857404379084ad",
      "930e64b1c07640b9ac317b045cf66234",
      "d0f6d15bf8e846349c6a2ca6f731dce0",
      "ae021b44c45d42ee9833ed61018e76fd",
      "2b21e721e6b04c718722f88defdff890",
      "b8986f5536b34544ac2b68bcf5eacfb2",
      "ef097813693f48a09bcefb50080ee121",
      "63fd5220a4c048759037f25fc463dfda",
      "9ca5a83eed0e46ac876d98d02badc38f",
      "cc9b8f290ed14387a233bbddf26a13e3",
      "1e1f2b9f2bf740e7b1233b13f851ffa3",
      "f91ac399d6514915acd2939ce216719a",
      "1f9c2851767c472797b639d62c023b86",
      "7cf56b6487d1432bb020c66fa7e0eb13",
      "d4d37f7d8e6e4598ba6dccba8532c99e",
      "f214e8c02ec74c6f8939431e961ba2de",
      "3bfa735716d647c984b5f3924a1b165d",
      "4ac36e9642ca4bb09cd371608d2f19e9",
      "8981c21234f74980925c297be4ba9b5f",
      "ec8852a1ac68491da70ad13d5d5eda02",
      "8ae52244a85749058aff873d8c2c7188",
      "ef9eaa2718ff4a169764c0f5148c3164",
      "5ad99e92edd1486ab5fb8ca560edf81c",
      "a133b09c9bc9484286d65e0aef25c470",
      "7bd83ff07e7c4b29adacc5c52c52e080",
      "45f4fa9f1ec640cb9bf55062421b7d72",
      "6d253523f9af4086a82651a5bb22888d",
      "9f6943bcf92a4c57928a2e66848d16dd"
     ]
    },
    "id": "4lv7JyE2f63y",
    "outputId": "3d3ad53f-de98-4b3c-ab26-a2ea391dc417"
   },
   "source": [
    "# return input_ids, attention_masks, labels\n",
    "input_ids, attention_masks, labels = data_process(df_copy[\"tweets\"], df_copy[\"sentiments\"])\n",
    "\n",
    "\n",
    "input_ids.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definations"
   ],
   "id": "c1fe6ce40fa99ff"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "M2DA5hBVf68h",
   "metadata": {
    "id": "M2DA5hBVf68h"
   },
   "source": [
    "import gc\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BERT_CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(BERT_CNN, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=13, kernel_size=(3, 768), padding=(1, 0))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(3, 1), stride=1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(442, num_classes)  # Adjust the output size to match the number of classes\n",
    "        self.flat = nn.Flatten()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, sent_id, mask):\n",
    "        cls_hs = self.bert(input_ids=sent_id, attention_mask=mask, return_dict=False, output_hidden_states=True)\n",
    "        x = cls_hs[0].unsqueeze(1)  # Add a channel dimension\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.fc(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "class BERT_LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, hidden_size, num_layers, bidirectional):\n",
    "        super(BERT_LSTM, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.lstm = nn.LSTM(input_size=768, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(hidden_size * 2 if bidirectional else hidden_size, num_classes)  # Adjust the output size to match the number of classes\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, sent_id, mask):\n",
    "        cls_hs = self.bert(input_ids=sent_id, attention_mask=mask, return_dict=False, output_hidden_states=True)\n",
    "        x = cls_hs[0]\n",
    "        x = self.dropout(x)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        x = self.fc(lstm_out[:, -1, :])  # Use the final hidden state for classification\n",
    "        return self.softmax(x)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ySo3WyO_f6_d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ySo3WyO_f6_d",
    "outputId": "4d2892ac-fea6-4fc1-b642-f9dbb80a13c9"
   },
   "source": [
    "input_ids.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "XwjLOfaZf7Bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "XwjLOfaZf7Bc",
    "outputId": "8bd1026b-6bdb-4bbe-b057-88fad4eb4604"
   },
   "source": [
    "# df = pd.DataFrame(list(zip(input_ids, attention_masks)), columns=['input_ids', 'attention_masks'])\n",
    "dataset = pd.DataFrame({'input_ids': list(input_ids), 'attention_masks': list(attention_masks)}, columns=['input_ids', 'attention_masks'])\n",
    "dataset"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "m4Cn7PMff7D6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4Cn7PMff7D6",
    "outputId": "d84ef36c-6ba1-4a7d-f57c-dd72085fefa4"
   },
   "source": [
    "dataset.columns"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "sS4Qus8Cf7HI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sS4Qus8Cf7HI",
    "outputId": "bdbb616a-5e17-4f55-c3d0-30334a71917a"
   },
   "source": [
    "labels = labels.astype(np.int64)\n",
    "labels"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "EKUk3uNDf7L3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EKUk3uNDf7L3",
    "outputId": "36c1f5eb-bc76-421f-c120-06c4648e73bf"
   },
   "source": [
    "(labels.astype(np.int64)).dtype"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT CNN MODEL"
   ],
   "id": "7b0addcb1408fe8a"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "rOcCmSGTf7PE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rOcCmSGTf7PE",
    "outputId": "813a353a-0212-41c9-b055-1c0b11baecb7"
   },
   "source": [
    "import gc\n",
    "#import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from transformers import AutoModel\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "test_text = dataset\n",
    "test_labels = labels\n",
    "\n",
    "\n",
    "# del temp_text\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# train_count = len(train_labels)\n",
    "test_count = len(test_labels)\n",
    "# val_count = len(val_labels)\n",
    "\n",
    "# import BERT-base pre-trained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# for test set\n",
    "test_seq = torch.tensor(test_text['input_ids'].tolist())\n",
    "test_mask = torch.tensor(test_text['attention_masks'].tolist())\n",
    "test_y = torch.tensor(test_labels.tolist())\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Create DataLoaders ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Freeze BERT Parameters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_CNN(num_classes=4)\n",
    "model_state = torch.load(\"/content/bert_cnn_model.pth\")\n",
    "model.load_state_dict(model_state)\n",
    "# model = BERT_LSTM(num_classes=4, hidden_size=128, num_layers=2, bidirectional=True)\n",
    "# push the model to GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "\n",
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "\n",
    "# loss function\n",
    "#cross_entropy = nn.NLLLoss(weight=weights)\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "nnloss = nn.NLLLoss()\n",
    "\n",
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "\n",
    "\n",
    "def get_accuracy_per_batch(oglabels, predlabels):\n",
    "  count = 0\n",
    "  for i in range(len(oglabels)):\n",
    "    if oglabels[i] == predlabels[i]:\n",
    "      count+=1\n",
    "\n",
    "  return count/len(oglabels)\n",
    "\n",
    "def get_total_accuracy(acc_list):\n",
    "  return sum(acc_list)/len(acc_list)\n",
    "\n",
    "\n",
    "# function to train the model\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    # empty list to save model predictions\n",
    "    total_preds = []\n",
    "    accuracy = 0\n",
    "    # iterate over batches\n",
    "    total = len(train_dataloader)\n",
    "    acc_list = []\n",
    "\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        step = i+1\n",
    "        percent = \"{0:.2f}\".format(100 * (step / float(total)))\n",
    "        lossp = \"{0:.2f}\".format(total_loss/(total*batch_size))\n",
    "        filledLength = int(100 * step // total)\n",
    "        bar = '█' * filledLength + '>'  *(filledLength < 100) + '.' * (99 - filledLength)\n",
    "        print(f'\\rBatch {step}/{total} |{bar}| {percent}% complete, loss={lossp}, accuracy={accuracy}', end='')\n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        del batch\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # clear previously calculated gradients\n",
    "        model.zero_grad()\n",
    "        # get model predictions for the current batch\n",
    "\n",
    "        preds = model(sent_id.to(device).long(), mask)\n",
    "        predicted_labels = torch.argmax(preds, dim=1)\n",
    "\n",
    "        # print(f\"Predictions are : {predicted_labels}\")\n",
    "        # print(f\"Labels are : {labels}\")\n",
    "        accuracy = get_accuracy_per_batch(labels, predicted_labels)\n",
    "        acc_list.append(accuracy)\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(preds, labels)\n",
    "        # print(f\"Loss {loss}, loss item: {loss.item}\")\n",
    "        # add on to the total loss\n",
    "        total_loss += float(loss.item())\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        # append the model predictions\n",
    "        total_preds.append(preds.detach().cpu().numpy())\n",
    "        # break\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / (len(train_dataloader)*batch_size)\n",
    "\n",
    "    # avg accuracy\n",
    "    total_accuracy = get_total_accuracy(acc_list)\n",
    "\n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    # returns the loss and predictions\n",
    "    return avg_loss, total_preds, total_accuracy\n",
    "\n",
    "\n",
    "\n",
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "    print(\"\\n\\nEvaluating...\")\n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    accuracy = 0\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "    acc_list = []\n",
    "    # iterate over batches\n",
    "    total = len(val_dataloader)\n",
    "    for i, batch in enumerate(val_dataloader):\n",
    "        step = i+1\n",
    "        percent = \"{0:.2f}\".format(100 * (step / float(total)))\n",
    "        lossp = \"{0:.2f}\".format(total_loss/(total*batch_size))\n",
    "        filledLength = int(100 * step // total)\n",
    "        bar = '█' * filledLength + '>' * (filledLength < 100) + '.' * (99 - filledLength)\n",
    "        print(f'\\rBatch {step}/{total} |{bar}| {percent}% complete, loss={lossp}, accuracy={total_accuracy}', end='')\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        del batch\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds, labels)\n",
    "            total_loss += float(loss.item())\n",
    "            total_preds.append(preds.detach().cpu().numpy())\n",
    "            predicted_labels = torch.argmax(preds, dim=1)\n",
    "\n",
    "\n",
    "            accuracy = get_accuracy_per_batch(labels, predicted_labels)\n",
    "            acc_list.append(accuracy)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / (len(val_dataloader)*batch_size)\n",
    "    # avg accuracy\n",
    "    total_accuracy = get_total_accuracy(acc_list)\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds = np.concatenate(total_preds, axis=0)\n",
    "    return avg_loss, total_preds, total_accuracy\n",
    "\n",
    "\n",
    "print(device)\n",
    "# get predictions for test data\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq.to(device), test_mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "print(\"Performance:\")\n",
    "# model's performance\n",
    "preds = np.argmax(preds, axis=1)\n",
    "print('Classification Report')\n",
    "print(classification_report(test_y, preds))\n",
    "\n",
    "print(\"Accuracy: \" + str(accuracy_score(test_y, preds)))\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT LSTM MODEL"
   ],
   "id": "3d105621909d78f3"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "FjsGd0YpgggR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FjsGd0YpgggR",
    "outputId": "c2da2241-b313-474a-bf51-beb6412ad7f1"
   },
   "source": [
    "import gc\n",
    "#import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from transformers import AutoModel\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "test_text = dataset\n",
    "test_labels = labels\n",
    "# train_text, temp_text, train_labels, temp_labels = train_test_split(dataset, labels,\n",
    "#                              random_state=2018, test_size=0.2, stratify=labels)\n",
    "\n",
    "# val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,\n",
    "#                          random_state=2018, test_size=0.5, stratify=temp_labels)\n",
    "\n",
    "\n",
    "# del temp_text\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# train_count = len(train_labels)\n",
    "test_count = len(test_labels)\n",
    "# val_count = len(val_labels)\n",
    "\n",
    "# import BERT-base pre-trained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# for test set\n",
    "test_seq = torch.tensor(test_text['input_ids'].tolist())\n",
    "test_mask = torch.tensor(test_text['attention_masks'].tolist())\n",
    "test_y = torch.tensor(test_labels.tolist())\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Create DataLoaders ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Freeze BERT Parameters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_LSTM(num_classes=4, hidden_size=128, num_layers=2, bidirectional=False)\n",
    "model_state = torch.load(\"/content/bert_lstm_model.pth\")\n",
    "model.load_state_dict(model_state)\n",
    "# model = BERT_LSTM(num_classes=4, hidden_size=128, num_layers=2, bidirectional=True)\n",
    "# push the model to GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "\n",
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "\n",
    "# loss function\n",
    "#cross_entropy = nn.NLLLoss(weight=weights)\n",
    "cross_entropy = nn.NLLLoss()\n",
    "# cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "nnloss = nn.NLLLoss()\n",
    "\n",
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "\n",
    "\n",
    "def get_accuracy_per_batch(oglabels, predlabels):\n",
    "  count = 0\n",
    "  for i in range(len(oglabels)):\n",
    "    if oglabels[i] == predlabels[i]:\n",
    "      count+=1\n",
    "\n",
    "  return count/len(oglabels)\n",
    "\n",
    "def get_total_accuracy(acc_list):\n",
    "  return sum(acc_list)/len(acc_list)\n",
    "\n",
    "\n",
    "# function to train the model\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    # empty list to save model predictions\n",
    "    total_preds = []\n",
    "    accuracy = 0\n",
    "    # iterate over batches\n",
    "    total = len(train_dataloader)\n",
    "    acc_list = []\n",
    "\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        step = i+1\n",
    "        percent = \"{0:.2f}\".format(100 * (step / float(total)))\n",
    "        lossp = \"{0:.2f}\".format(total_loss/(total*batch_size))\n",
    "        filledLength = int(100 * step // total)\n",
    "        bar = '█' * filledLength + '>'  *(filledLength < 100) + '.' * (99 - filledLength)\n",
    "        print(f'\\rBatch {step}/{total} |{bar}| {percent}% complete, loss={lossp}, accuracy={accuracy}', end='')\n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        del batch\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # clear previously calculated gradients\n",
    "        model.zero_grad()\n",
    "        # get model predictions for the current batch\n",
    "\n",
    "        preds = model(sent_id.to(device).long(), mask)\n",
    "        predicted_labels = torch.argmax(preds, dim=1)\n",
    "\n",
    "        # print(f\"Predictions are : {predicted_labels}\")\n",
    "        # print(f\"Labels are : {labels}\")\n",
    "        accuracy = get_accuracy_per_batch(labels, predicted_labels)\n",
    "        acc_list.append(accuracy)\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(preds, labels)\n",
    "        # print(f\"Loss {loss}, loss item: {loss.item}\")\n",
    "        # add on to the total loss\n",
    "        total_loss += float(loss.item())\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        # append the model predictions\n",
    "        total_preds.append(preds.detach().cpu().numpy())\n",
    "        # break\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / (len(train_dataloader)*batch_size)\n",
    "\n",
    "    # avg accuracy\n",
    "    total_accuracy = get_total_accuracy(acc_list)\n",
    "\n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    # returns the loss and predictions\n",
    "    return avg_loss, total_preds, total_accuracy\n",
    "\n",
    "\n",
    "\n",
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "    print(\"\\n\\nEvaluating...\")\n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    accuracy = 0\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "    acc_list = []\n",
    "    # iterate over batches\n",
    "    total = len(val_dataloader)\n",
    "    for i, batch in enumerate(val_dataloader):\n",
    "        step = i+1\n",
    "        percent = \"{0:.2f}\".format(100 * (step / float(total)))\n",
    "        lossp = \"{0:.2f}\".format(total_loss/(total*batch_size))\n",
    "        filledLength = int(100 * step // total)\n",
    "        bar = '█' * filledLength + '>' * (filledLength < 100) + '.' * (99 - filledLength)\n",
    "        print(f'\\rBatch {step}/{total} |{bar}| {percent}% complete, loss={lossp}, accuracy={total_accuracy}', end='')\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        del batch\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds, labels)\n",
    "            total_loss += float(loss.item())\n",
    "            total_preds.append(preds.detach().cpu().numpy())\n",
    "            predicted_labels = torch.argmax(preds, dim=1)\n",
    "\n",
    "\n",
    "            accuracy = get_accuracy_per_batch(labels, predicted_labels)\n",
    "            acc_list.append(accuracy)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / (len(val_dataloader)*batch_size)\n",
    "    # avg accuracy\n",
    "    total_accuracy = get_total_accuracy(acc_list)\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds = np.concatenate(total_preds, axis=0)\n",
    "    return avg_loss, total_preds, total_accuracy\n",
    "\n",
    "\n",
    "print(device)\n",
    "# get predictions for test data\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq.to(device), test_mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "print(\"Performance:\")\n",
    "# model's performance\n",
    "preds = np.argmax(preds, axis=1)\n",
    "print('Classification Report')\n",
    "print(classification_report(test_y, preds))\n",
    "\n",
    "print(\"Accuracy: \" + str(accuracy_score(test_y, preds)))\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT BILSTM MODEL"
   ],
   "id": "18f0d0720aacf9b2"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "IJdgdYFNgglD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJdgdYFNgglD",
    "outputId": "8c460c23-dac7-4df9-c2df-620be366ca83"
   },
   "source": [
    "import gc\n",
    "#import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from transformers import AutoModel\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "test_text = dataset\n",
    "test_labels = labels\n",
    "# train_text, temp_text, train_labels, temp_labels = train_test_split(dataset, labels,\n",
    "#                              random_state=2018, test_size=0.2, stratify=labels)\n",
    "\n",
    "# val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,\n",
    "#                          random_state=2018, test_size=0.5, stratify=temp_labels)\n",
    "\n",
    "\n",
    "# del temp_text\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# train_count = len(train_labels)\n",
    "test_count = len(test_labels)\n",
    "# val_count = len(val_labels)\n",
    "\n",
    "# import BERT-base pre-trained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# for test set\n",
    "test_seq = torch.tensor(test_text['input_ids'].tolist())\n",
    "test_mask = torch.tensor(test_text['attention_masks'].tolist())\n",
    "test_y = torch.tensor(test_labels.tolist())\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Create DataLoaders ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Freeze BERT Parameters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_LSTM(num_classes=4, hidden_size=128, num_layers=2, bidirectional=True)\n",
    "model_state = torch.load(\"/content/bert_bilstm_model.pth\")\n",
    "model.load_state_dict(model_state)\n",
    "# model = BERT_LSTM(num_classes=4, hidden_size=128, num_layers=2, bidirectional=True)\n",
    "# push the model to GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "\n",
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "\n",
    "# loss function\n",
    "#cross_entropy = nn.NLLLoss(weight=weights)\n",
    "cross_entropy = nn.NLLLoss()\n",
    "# cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "nnloss = nn.NLLLoss()\n",
    "\n",
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "\n",
    "\n",
    "def get_accuracy_per_batch(oglabels, predlabels):\n",
    "  count = 0\n",
    "  for i in range(len(oglabels)):\n",
    "    if oglabels[i] == predlabels[i]:\n",
    "      count+=1\n",
    "\n",
    "  return count/len(oglabels)\n",
    "\n",
    "def get_total_accuracy(acc_list):\n",
    "  return sum(acc_list)/len(acc_list)\n",
    "\n",
    "\n",
    "# function to train the model\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    # empty list to save model predictions\n",
    "    total_preds = []\n",
    "    accuracy = 0\n",
    "    # iterate over batches\n",
    "    total = len(train_dataloader)\n",
    "    acc_list = []\n",
    "\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        step = i+1\n",
    "        percent = \"{0:.2f}\".format(100 * (step / float(total)))\n",
    "        lossp = \"{0:.2f}\".format(total_loss/(total*batch_size))\n",
    "        filledLength = int(100 * step // total)\n",
    "        bar = '█' * filledLength + '>'  *(filledLength < 100) + '.' * (99 - filledLength)\n",
    "        print(f'\\rBatch {step}/{total} |{bar}| {percent}% complete, loss={lossp}, accuracy={accuracy}', end='')\n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        del batch\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # clear previously calculated gradients\n",
    "        model.zero_grad()\n",
    "        # get model predictions for the current batch\n",
    "\n",
    "        preds = model(sent_id.to(device).long(), mask)\n",
    "        predicted_labels = torch.argmax(preds, dim=1)\n",
    "\n",
    "        # print(f\"Predictions are : {predicted_labels}\")\n",
    "        # print(f\"Labels are : {labels}\")\n",
    "        accuracy = get_accuracy_per_batch(labels, predicted_labels)\n",
    "        acc_list.append(accuracy)\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(preds, labels)\n",
    "        # print(f\"Loss {loss}, loss item: {loss.item}\")\n",
    "        # add on to the total loss\n",
    "        total_loss += float(loss.item())\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        # append the model predictions\n",
    "        total_preds.append(preds.detach().cpu().numpy())\n",
    "        # break\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / (len(train_dataloader)*batch_size)\n",
    "\n",
    "    # avg accuracy\n",
    "    total_accuracy = get_total_accuracy(acc_list)\n",
    "\n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    # returns the loss and predictions\n",
    "    return avg_loss, total_preds, total_accuracy\n",
    "\n",
    "\n",
    "\n",
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "    print(\"\\n\\nEvaluating...\")\n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    accuracy = 0\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "    acc_list = []\n",
    "    # iterate over batches\n",
    "    total = len(val_dataloader)\n",
    "    for i, batch in enumerate(val_dataloader):\n",
    "        step = i+1\n",
    "        percent = \"{0:.2f}\".format(100 * (step / float(total)))\n",
    "        lossp = \"{0:.2f}\".format(total_loss/(total*batch_size))\n",
    "        filledLength = int(100 * step // total)\n",
    "        bar = '█' * filledLength + '>' * (filledLength < 100) + '.' * (99 - filledLength)\n",
    "        print(f'\\rBatch {step}/{total} |{bar}| {percent}% complete, loss={lossp}, accuracy={total_accuracy}', end='')\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        del batch\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds, labels)\n",
    "            total_loss += float(loss.item())\n",
    "            total_preds.append(preds.detach().cpu().numpy())\n",
    "            predicted_labels = torch.argmax(preds, dim=1)\n",
    "\n",
    "\n",
    "            accuracy = get_accuracy_per_batch(labels, predicted_labels)\n",
    "            acc_list.append(accuracy)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / (len(val_dataloader)*batch_size)\n",
    "    # avg accuracy\n",
    "    total_accuracy = get_total_accuracy(acc_list)\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds = np.concatenate(total_preds, axis=0)\n",
    "    return avg_loss, total_preds, total_accuracy\n",
    "\n",
    "\n",
    "print(device)\n",
    "# get predictions for test data\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq.to(device), test_mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "print(\"Performance:\")\n",
    "# model's performance\n",
    "preds = np.argmax(preds, axis=1)\n",
    "print('Classification Report')\n",
    "print(classification_report(test_y, preds))\n",
    "\n",
    "print(\"Accuracy: \" + str(accuracy_score(test_y, preds)))\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DS_aMguJggos",
   "metadata": {
    "id": "DS_aMguJggos"
   },
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5F80ZxPHggsF",
   "metadata": {
    "id": "5F80ZxPHggsF"
   },
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AcKvi-6zggvT",
   "metadata": {
    "id": "AcKvi-6zggvT"
   },
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1850bfffad004758a1eff8f0214ca096": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e35cd93cc9345148a5a0f8a3f6eee06",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e07bec675dd84907b9864024c52538da",
      "value": 28
     }
    },
    "1e1f2b9f2bf740e7b1233b13f851ffa3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f9c2851767c472797b639d62c023b86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "22f3a1570e4048fa87a0a67793708ea8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bb0bff7c20144c879e3a9857bfbfe4a0",
       "IPY_MODEL_f1c6b457aa5443ed873b4104c951fd1a",
       "IPY_MODEL_4cf79df228e14178ac64ebc11c9458ff"
      ],
      "layout": "IPY_MODEL_aca06649bfb6448699b303b9104a6e87"
     }
    },
    "2b21e721e6b04c718722f88defdff890": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "301a18fe83224f73babb22e264ee6a91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38e2710afa6a4e7980776e356d81ef36",
      "placeholder": "​",
      "style": "IPY_MODEL_e8c8569152ba4455961ed447fbc11c5c",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "38e2710afa6a4e7980776e356d81ef36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bb0fb7dc5c54f3f8e16f4cb25d9c8e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_301a18fe83224f73babb22e264ee6a91",
       "IPY_MODEL_1850bfffad004758a1eff8f0214ca096",
       "IPY_MODEL_771b3019c7364f43879a0632d946015e"
      ],
      "layout": "IPY_MODEL_4826a9443d90449bb9112f005a73b0f9"
     }
    },
    "3bfa735716d647c984b5f3924a1b165d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4050f16f9f0144babf857404379084ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45f4fa9f1ec640cb9bf55062421b7d72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4826a9443d90449bb9112f005a73b0f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ac36e9642ca4bb09cd371608d2f19e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8981c21234f74980925c297be4ba9b5f",
       "IPY_MODEL_ec8852a1ac68491da70ad13d5d5eda02",
       "IPY_MODEL_8ae52244a85749058aff873d8c2c7188"
      ],
      "layout": "IPY_MODEL_ef9eaa2718ff4a169764c0f5148c3164"
     }
    },
    "4cf79df228e14178ac64ebc11c9458ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b21e721e6b04c718722f88defdff890",
      "placeholder": "​",
      "style": "IPY_MODEL_b8986f5536b34544ac2b68bcf5eacfb2",
      "value": " 232k/232k [00:00&lt;00:00, 12.3MB/s]"
     }
    },
    "4e35cd93cc9345148a5a0f8a3f6eee06": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ad99e92edd1486ab5fb8ca560edf81c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63fd5220a4c048759037f25fc463dfda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f91ac399d6514915acd2939ce216719a",
      "placeholder": "​",
      "style": "IPY_MODEL_1f9c2851767c472797b639d62c023b86",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    },
    "6d253523f9af4086a82651a5bb22888d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "771b3019c7364f43879a0632d946015e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_771ed2bf8a2549e5a7f35e4d9a6d3311",
      "placeholder": "​",
      "style": "IPY_MODEL_bc41aaa5134c4071a126e1e771076441",
      "value": " 28.0/28.0 [00:00&lt;00:00, 1.48kB/s]"
     }
    },
    "771ed2bf8a2549e5a7f35e4d9a6d3311": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7bd83ff07e7c4b29adacc5c52c52e080": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7cf56b6487d1432bb020c66fa7e0eb13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8981c21234f74980925c297be4ba9b5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ad99e92edd1486ab5fb8ca560edf81c",
      "placeholder": "​",
      "style": "IPY_MODEL_a133b09c9bc9484286d65e0aef25c470",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "8ae52244a85749058aff873d8c2c7188": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d253523f9af4086a82651a5bb22888d",
      "placeholder": "​",
      "style": "IPY_MODEL_9f6943bcf92a4c57928a2e66848d16dd",
      "value": " 570/570 [00:00&lt;00:00, 43.9kB/s]"
     }
    },
    "930e64b1c07640b9ac317b045cf66234": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ca5a83eed0e46ac876d98d02badc38f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7cf56b6487d1432bb020c66fa7e0eb13",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d4d37f7d8e6e4598ba6dccba8532c99e",
      "value": 466062
     }
    },
    "9f6943bcf92a4c57928a2e66848d16dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a133b09c9bc9484286d65e0aef25c470": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aca06649bfb6448699b303b9104a6e87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae021b44c45d42ee9833ed61018e76fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b8986f5536b34544ac2b68bcf5eacfb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb0bff7c20144c879e3a9857bfbfe4a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4050f16f9f0144babf857404379084ad",
      "placeholder": "​",
      "style": "IPY_MODEL_930e64b1c07640b9ac317b045cf66234",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "bc41aaa5134c4071a126e1e771076441": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cc9b8f290ed14387a233bbddf26a13e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f214e8c02ec74c6f8939431e961ba2de",
      "placeholder": "​",
      "style": "IPY_MODEL_3bfa735716d647c984b5f3924a1b165d",
      "value": " 466k/466k [00:00&lt;00:00, 30.0MB/s]"
     }
    },
    "d0f6d15bf8e846349c6a2ca6f731dce0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4d37f7d8e6e4598ba6dccba8532c99e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e07bec675dd84907b9864024c52538da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e8c8569152ba4455961ed447fbc11c5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec8852a1ac68491da70ad13d5d5eda02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7bd83ff07e7c4b29adacc5c52c52e080",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_45f4fa9f1ec640cb9bf55062421b7d72",
      "value": 570
     }
    },
    "ef097813693f48a09bcefb50080ee121": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_63fd5220a4c048759037f25fc463dfda",
       "IPY_MODEL_9ca5a83eed0e46ac876d98d02badc38f",
       "IPY_MODEL_cc9b8f290ed14387a233bbddf26a13e3"
      ],
      "layout": "IPY_MODEL_1e1f2b9f2bf740e7b1233b13f851ffa3"
     }
    },
    "ef9eaa2718ff4a169764c0f5148c3164": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1c6b457aa5443ed873b4104c951fd1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0f6d15bf8e846349c6a2ca6f731dce0",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ae021b44c45d42ee9833ed61018e76fd",
      "value": 231508
     }
    },
    "f214e8c02ec74c6f8939431e961ba2de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f91ac399d6514915acd2939ce216719a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
