{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ],
   "id": "23bab2ac96630d34"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a47f1ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4a47f1ef",
    "outputId": "f6081146-e0ef-4409-9320-7f91b8329414"
   },
   "source": [
    "# importing libraries\n",
    "from wordcloud import WordCloud\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as goa\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7daDN0eKM7bH",
   "metadata": {
    "id": "7daDN0eKM7bH"
   },
   "source": [
    "# loading dataset\n",
    "df = pd.read_csv(\"data/twitter_training.csv\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c4bcf9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "6c4bcf9c",
    "outputId": "4a1db9ca-787a-41c6-ee8c-fa5a5d9aa47c",
    "scrolled": true
   },
   "source": [
    "# Label the columns and drop column \"place\"\n",
    "df.columns = [\"tweet_id\",\"place\", \"sentiments\", \"tweets\"]\n",
    "df = df.drop(\"place\", axis=1)\n",
    "df"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4fb5568a",
   "metadata": {
    "id": "4fb5568a"
   },
   "source": [
    "# Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21afdf30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21afdf30",
    "outputId": "dd2a2a63-ff3a-45a0-8433-f09a5f4b8979"
   },
   "source": [
    "df.info()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d2228d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "3d2228d0",
    "outputId": "c19394b9-5231-4a29-dcc4-0d039533acf1",
    "scrolled": true
   },
   "source": [
    "# Identify inconsistencies\n",
    "#The code `duplicate_rows = df[df.duplicated()]` is identifying and storing the duplicate rows in the DataFrame `df`. The `df.duplicated()` function returns a boolean Series indicating whether each row is a duplicate or not. By passing this boolean Series as a filter to the DataFrame `df`, only the duplicate rows are selected and stored in the variable `duplicate_rows`.\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "duplicate_rows"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f9f4465",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f9f4465",
    "outputId": "67fec3c2-ae92-4b3e-96d3-bb620f28d792"
   },
   "source": [
    "# Identify missing values\n",
    "#The code is calculating the number of missing values in each column of the DataFrame `df`. It uses the `isna()` method to check for missing values and the `sum()` method to calculate the total number of missing values in each column. The result is stored in the variable `missing_values`.\n",
    "missing_values = df.isna().sum()\n",
    "missing_values"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74e841e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "74e841e9",
    "outputId": "f8c3bdc4-1873-467f-ab6b-6adee1ac4296"
   },
   "source": [
    "# removing duplicates\n",
    "\n",
    "df.drop_duplicates(inplace = True)\n",
    "\n",
    "# Remove the duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# convert tweets to type str\n",
    "\n",
    "df['tweets'] = df['tweets'].astype(str)\n",
    "\n",
    "\n",
    "# loading stopwords\n",
    "stopw = set(stopwords.words(\"english\"))\n",
    "\n",
    "print(stopw)\n",
    "\n",
    "# word tokens in lower case\n",
    "df[\"tweets\"] = df['tweets'].apply(lambda x: ' '.join(\n",
    "    [word.lower() for word in x.split() if word.lower() not in stopw]))\n",
    "\n",
    "# convert list to string\n",
    "def convert_list_to_str(l):\n",
    "    st = \"\"\n",
    "    for i in l:\n",
    "        st = st+i+\" \"\n",
    "    st = st[:-1]\n",
    "    return st\n",
    "\n",
    "# filter tokens by keeping only letters and numbers\n",
    "tokenizer = RegexpTokenizer(r'\\w+|\\d+')\n",
    "df[\"tweets_new\"] = df[\"tweets\"].apply(tokenizer.tokenize)\n",
    "df[\"tweets_new\"] = df[\"tweets_new\"].apply(convert_list_to_str)\n",
    "\n",
    "\n",
    "df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c91af7f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 906
    },
    "id": "c91af7f4",
    "outputId": "42d24d1a-9f3c-48e4-b618-5c303774962f"
   },
   "source": [
    "# Lemmetization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# parts of speech from wordnet\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # Default to noun if no mapping found\n",
    "\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    words = sentence.split()\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    lemmatized_words = [lemmatizer.lemmatize(\n",
    "        word, get_wordnet_pos(pos_tag)) for word, pos_tag in pos_tags]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "df[\"tweets_new\"] = df[\"tweets_new\"].apply(lemmatize_sentence)\n",
    "print(df)\n",
    "\n",
    "# copying columns \n",
    "df[\"tweets\"] = df[\"tweets_new\"]\n",
    "\n",
    "df = df.drop(columns=[\"tweets_new\"])\n",
    "\n",
    "#fill 0 in mum\n",
    "df['tweets'] = df['tweets'].fillna(0)\n",
    "\n",
    "# Save the dataframe\n",
    "df.to_csv(\"tweet_clean.csv\", index=False)\n",
    "df\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a392a91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7a392a91",
    "outputId": "dd8216b7-3f4e-49ef-b0cd-c79c9f5c0cfe"
   },
   "source": [
    "#check null\n",
    "df['tweets'].isnull().sum()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0609e972",
   "metadata": {
    "id": "0609e972"
   },
   "source": [
    "# Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb76673b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "cb76673b",
    "outputId": "8adbe945-84a8-4525-a79f-3e1b773b5c67"
   },
   "source": [
    "#`df.describe().T` is transposing the output of the `describe()` method on a DataFrame `df`. The `describe()` method provides summary statistics of the numerical columns in the DataFrame, such as count, mean, standard deviation, minimum, maximum, and quartiles. By applying `.T` after `describe()`, the output is transposed, meaning the rows become columns and vice versa. This can be useful for better readability or for further analysis of the summary statistics.\n",
    "df.describe().T"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "006b4366",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "id": "006b4366",
    "outputId": "bbe4982a-a811-47ce-9241-94036c711860"
   },
   "source": [
    "# Plot countplots for categories of tweets with their numbers\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='sentiments', data=df)\n",
    "for container in plt.gca().containers:\n",
    "    plt.gca().bar_label(container, fmt='%.2f')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a4cc280",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "1a4cc280",
    "outputId": "7ec2eefd-3818-49c8-fe65-5c78dc71609a"
   },
   "source": [
    "# Ordinal encode sentiments\n",
    "\n",
    "df_copy = df.copy()\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "# Every single column with categorical values will be converted.\n",
    "object_cols = ['sentiments']\n",
    "df_copy[object_cols] = df_copy[object_cols].astype(str)\n",
    "\n",
    "df_copy[object_cols] = ordinal_encoder.fit_transform(df_copy[object_cols])\n",
    "\n",
    "df_copy.head()\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "# Every single column with categorical values will be converted.\n",
    "object_cols = ['tweet_id', 'sentiments', 'tweets']\n",
    "df[object_cols] = df[object_cols].astype(str)\n",
    "\n",
    "df[object_cols] = ordinal_encoder.fit_transform(df[object_cols])\n",
    "\n",
    "df.head()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "963d20b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711
    },
    "id": "963d20b9",
    "outputId": "d79b88d9-2f17-4aa9-a2df-87784ce90c50"
   },
   "source": [
    "# Extract the sentiment words\n",
    "\n",
    "negative_words = clean_df[clean_df['sentiments'] == 'Negative']['tweets'].tolist()\n",
    "neutral_words = clean_df[clean_df['sentiments'] == 'Neutral']['tweets'].tolist()\n",
    "irrelevant_words = clean_df[clean_df['sentiments'] == 'Irrelevant']['tweets'].tolist()\n",
    "\n",
    "negative_words = [str(word) for word in negative_words]\n",
    "neutral_words = [str(word) for word in neutral_words]\n",
    "irrelevant_words = [str(word) for word in irrelevant_words]\n",
    "\n",
    "\n",
    "negative_wordcloud = WordCloud(width=1000, height=500).generate(' '.join(negative_words))\n",
    "neutral_wordcloud = WordCloud(width=1000, height=500).generate(' '.join(neutral_words))\n",
    "irrelevant_wordcloud = WordCloud(width=1000, height=500).generate(' '.join(irrelevant_words))\n",
    "\n",
    "# Display the word clouds\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(negative_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.title('Negative')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(neutral_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.title('Neutral')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(irrelevant_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.title('Irrelevant')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(positive_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.title('Positive')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bf40ce1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bf40ce1",
    "outputId": "1d6d2bf7-d184-4a62-9bf7-967561e05083"
   },
   "source": [
    "# print unique sentiments count\n",
    "print(df['sentiments'].nunique())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "88771d80",
   "metadata": {
    "id": "88771d80"
   },
   "source": [
    "# CNN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9319eba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9319eba",
    "outputId": "558b0acf-3d77-4e32-9430-4026360bfbc5"
   },
   "source": [
    "!pip install transformers"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe9afbbc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fe9afbbc",
    "outputId": "b2b0f249-e91c-47ae-b25c-9f246fe550cb"
   },
   "source": [
    "!pip install tensorflow"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97b06215",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "97b06215",
    "outputId": "4ba88c3d-9889-43fd-8cc5-4292c660432c"
   },
   "source": [
    "# Import necessary libraries and modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    Dense,\n",
    "    GlobalMaxPooling1D,\n",
    "    Embedding,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "import pandas as pd\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "df_train, df_test, y_train, y_test = train_test_split(\n",
    "    df_copy[\"tweets\"], df_copy[\"sentiments\"], test_size=0.3\n",
    ")\n",
    "\n",
    "# Tokenization of training data\n",
    "max_words = 10000\n",
    "tokenizer = Tokenizer(max_words)\n",
    "tokenizer.fit_on_texts(df_train)\n",
    "sequence_train = tokenizer.texts_to_sequences(df_train)\n",
    "sequence_test = tokenizer.texts_to_sequences(df_test)\n",
    "word2vec = tokenizer.word_index\n",
    "V = len(word2vec)\n",
    "print(\"dataset has %s number of independent tokens\" % V)\n",
    "\n",
    "# Padding sequences to ensure uniform length\n",
    "data_train = pad_sequences(sequence_train)\n",
    "T = data_train.shape[1]\n",
    "data_test = pad_sequences(sequence_test, maxlen=T)\n",
    "\n",
    "# Define the parameters for the CNN model\n",
    "D = 20  # Embedding dimension\n",
    "\n",
    "# Define the architecture of the CNN model\n",
    "i = Input((T,))\n",
    "x = Embedding(V + 1, D)(i)\n",
    "x = Conv1D(32, 3, activation=\"relu\")(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Conv1D(64, 3, activation=\"relu\")(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Conv1D(128, 3, activation=\"relu\")(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dense(4, activation=\"softmax\")(x)\n",
    "model = Model(i, x)\n",
    "model.summary()\n",
    "\n",
    "# Compile the CNN model\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Train the CNN model\n",
    "cnn_senti = model.fit(\n",
    "    data_train, y_train, validation_data=(data_test, y_test), epochs=50, batch_size=100\n",
    ")\n",
    "\n",
    "# Get the history dictionary\n",
    "history_dict = cnn_senti.history\n",
    "\n",
    "# Print the accuracy from the last epoch of CNN model\n",
    "print(\"CNN Accuracy: \", history_dict[\"accuracy\"][-1])\n",
    "\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "lolr8o_k4MtK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lolr8o_k4MtK",
    "outputId": "aeafbba5-0383-487c-85f7-e73a4d0f7b9a"
   },
   "source": [
    "model.save('CNN.h5')\n",
    "print('Model Saved!')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9111d87b",
   "metadata": {},
   "source": [
    "# LSTM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "132a12cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "132a12cf",
    "outputId": "2e73771d-f444-4d49-8489-8caf6c6fb947"
   },
   "source": [
    "###LSTM\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "labels = df_copy['sentiments'].values.tolist()\n",
    "num_labels = len(np.unique(labels))\n",
    "vocab_size = len(np.unique(df_copy['tweets'].values.tolist()))\n",
    "X_train = df_copy['tweets'].values.tolist()\n",
    "y_train = labels\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_train = to_categorical(y_train)\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "sequence_length = 100\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=sequence_length)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_padded, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "#LSTM Layers\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=256))\n",
    "model.add(LSTM(units=256, dropout=0.5, return_sequences=True, kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(units=256, dropout=0.5, return_sequences=False, kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "\n",
    "# Learning Rate Schedule and Early Stopping\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "lSTM_history = model.fit(X_train, y_train, epochs=20,validation_data=(X_val, y_val))\n",
    "\n",
    "\n",
    "\n",
    "# Get the history dictionary\n",
    "history_dict = lSTM_history.history\n",
    "\n",
    "\n",
    "# Print the train accuracy from the last epoch of LSTM model\n",
    "print(\"LSTM Accuracy: \", history_dict['accuracy'][-1])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "-8EJDYTySG0P",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-8EJDYTySG0P",
    "outputId": "c225e18f-0b68-4fed-856e-93acbab6a790"
   },
   "source": [
    "model.save('LSTM.h5')\n",
    "print('Model Saved!')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "114dfcb0",
   "metadata": {},
   "source": [
    "# BILSTM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77da8742",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77da8742",
    "outputId": "59e5bd37-cbe5-4c80-e900-629e19c1c820"
   },
   "source": [
    "#BILSTM\n",
    "\n",
    "labels = df_copy['sentiments'].values.tolist()\n",
    "num_labels = len(np.unique(labels))\n",
    "vocab_size = len(np.unique(df_copy['tweets'].values.tolist()))\n",
    "\n",
    "# Split the training dataset into input and output features\n",
    "X_train = df_copy['tweets'].values.tolist()\n",
    "y_train = labels\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_train = to_categorical(y_train)\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "sequence_length = 100  # or any number larger than your kernel size\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=sequence_length)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_padded, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Define the BILSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=128))\n",
    "model.add(Bidirectional(LSTM(units=128, dropout=0.5, return_sequences=True, kernel_regularizer=l2(0.01))))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Bidirectional(LSTM(units=128, dropout=0.5, return_sequences=False, kernel_regularizer=l2(0.01))))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "# Learning Rate Schedule and Early Stopping\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "bilstm_history = model.fit(X_train, y_train, epochs=15,validation_data=(X_val, y_val))\n",
    "\n",
    "# Print history\n",
    "print(history_dict.keys())\n",
    "\n",
    "\n",
    "# print train acuuracy of last epoch of BILSTM model\n",
    "print(\"BiLSTM Accuracy: \", history_dict['accuracy'][-1])\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "VjYkLDMRbGt3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VjYkLDMRbGt3",
    "outputId": "bdb92a8c-1139-4a3f-f252-2838ef695d39"
   },
   "source": [
    "model.save('BILSTM.h5')\n",
    "print('Model Saved!')"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
